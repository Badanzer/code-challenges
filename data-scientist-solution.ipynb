{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from google.cloud import bigquery\nimport pandas as pd\n\nclient = bigquery.Client()\n\nquery = \"\"\"\n SELECT \n token_address as addr,\n value as val,\n block_timestamp as time\nFROM\n`bigquery-public-data.crypto_ethereum.token_transfers` \n\nWHERE date(block_timestamp)>=\"2021-01-22\"\nLIMIT 1000000\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nquery_job = client.query(query)\n\niterator = query_job.result(timeout=30)\nrows = list(iterator)\n\n# Transform the rows into a nice pandas dataframe\ndf = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n\n# Look at the first 15\ndf.head(15)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show the token_address with the most transactions\nlisttop5=df.addr.value_counts()[:5].index.tolist()\nprint(listtop5)#print the top 5 most transacted coins\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"client = bigquery.Client()\n#get the token tiker and the decimals\nquery = \"\"\"\n SELECT \n address as addr,\n decimals as deci,\n name as name\nFROM\n`bigquery-public-data.crypto_ethereum.tokens` \n\"\"\"\n\nquery_job = client.query(query)\n\niterator = query_job.result(timeout=30)\nrows2 = list(iterator)\n#print (rows)\n# Transform the rows into a nice pandas dataframe\ndf2 = pd.DataFrame(data=[list(x.values()) for x in rows2], columns=list(rows2[0].keys()))\n\n# Look at the first 10\ndf2.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the top5 coins and extract the decimals + tiker for them\ndf['val'] = df['val'].astype(float)\n\ndigit=[0]*5 #generate two arrays\nname=[0]*5\n\ndigit[0]=df2.loc[df2['addr'] == listtop5[0]]['deci'].values #extract decimals and name for all top5 tokens\nname[0]=df2.loc[df2['addr'] == listtop5[0]]['name'].values\n\ndigit[1]=df2.loc[df2['addr'] == listtop5[1]]['deci'].values\nname[1]=df2.loc[df2['addr'] == listtop5[1]]['name'].values\n\ndigit[2]=df2.loc[df2['addr'] == listtop5[2]]['deci'].values\nname[2]=df2.loc[df2['addr'] == listtop5[2]]['name'].values\n\ndigit[3]=df2.loc[df2['addr'] == listtop5[3]]['deci'].values\nname[3]=df2.loc[df2['addr'] == listtop5[3]]['name'].values\n\ndigit[4]=df2.loc[df2['addr'] == listtop5[4]]['deci'].values\nname[4]=df2.loc[df2['addr'] == listtop5[4]]['name'].values\n\nfor x in range(0, 5): #check for not listed tokens\n    if listtop5[x]== \"0x6b175474e89094c44da98b954eedeac495271d0f\": #DAI\n        digit[x]=18\n        name[x]=[\"Dai Stablecoin\"]\n    if listtop5[x]== \"0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48\": # USD\n        digit[x]=6\n        name[x]=[\"USD Coin\"]\n#maybe there are some more tokens who need to be added\n        \nprint(digit)\nprint(name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the total volume of the top5 coins\nimport math\nvol0=df.loc[df['addr'] == listtop5[0], 'val'].sum() #collect all val in df when addr=var\nvol1=df.loc[df['addr'] == listtop5[1], 'val'].sum()\nvol2=df.loc[df['addr'] == listtop5[2], 'val'].sum()\nvol3=df.loc[df['addr'] == listtop5[3], 'val'].sum()\nvol4=df.loc[df['addr'] == listtop5[4], 'val'].sum()\n\n#get the correct volume\nvol0=vol0/math.pow(10,digit[0])\nvol1=vol1/math.pow(10,digit[1])\nvol2=vol2/math.pow(10,digit[2])\nvol3=vol3/math.pow(10,digit[3])\nvol4=vol4/math.pow(10,digit[4])\n\n\nprint(name[0],vol0,name[1],vol1,name[2],vol2,name[3],vol3,name[4],vol4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from google.cloud import bigquery\nimport pandas as pd\n\nclient = bigquery.Client()\n\n#here we could reduce the data to collect\n#maybe there is a way to take the top add to the query\nquery = \"\"\"\n SELECT \n token_address as addr,\n value as val,\n date(block_timestamp) as time\nFROM\n`bigquery-public-data.crypto_ethereum.token_transfers` \n\nWHERE date(block_timestamp)>=\"2021-01-20\"\nLIMIT 10000000\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_job = client.query(query)\n\niterator = query_job.result(timeout=30)\nrows = list(iterator)\n\n# Transform the rows into a nice pandas dataframe\ndf3 = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n\n# Look at the first 15\ndf3.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\ndf3['time'] = pd.to_datetime(df3['time']) #convert the time format\nqwert=[]\ntoken0=pd.DataFrame(qwert, columns=['day', 'transac'])#generat a empty dataframe\n\nfor x in range(0, 30): #move one month and check the transactions for a token\n    d=datetime.date.today() - datetime.timedelta(days=x) #generate the date\n    d=d.strftime(\"%Y-%m-%d\") #edit it in the correct format\n    a=df3[(df3[\"addr\"] == listtop5[0]) & (df3[\"time\"]==d)].count() #collect all transactions for this data\n    a=a[0] #filter it\n    token0.loc[x] =[d,a] #add data to the frame\nprint(name[0])\nprint (token0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qwert=[]\ntoken1=pd.DataFrame(qwert, columns=['day', 'transac'])#generat a empty dataframe\n\nfor x in range(0, 30): #move one month and check the transactions for a token\n    d=datetime.date.today() - datetime.timedelta(days=x) #generate the date\n    d=d.strftime(\"%Y-%m-%d\") #edit it in the correct format\n    a=df3[(df3[\"addr\"] == listtop5[1]) & (df3[\"time\"]==d)].count()#collect all transactions for this data\n    a=a[0]#filter it\n    token1.loc[x] =[d,a]#add data to the frame\nprint(name[1])\nprint (token1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}